{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/pitiwat/argument_wangchanberta/resolve/main/sentencepiece.bpe.model from cache at /home/mike/.cache/huggingface/transformers/f6e29e1206d1999d154e64bb8838e8ab5cb638d161dc6c3ee55e0e24d16dc88e.55fbe44df3c0d4d4b0f176ea9200b724f4cf138bb7ec54dc30097525d7ae4cad\n",
      "loading file https://huggingface.co/pitiwat/argument_wangchanberta/resolve/main/tokenizer.json from cache at /home/mike/.cache/huggingface/transformers/e6f40e59d2be2e28c24a0681d7c17b6e1a5ef31c2599cb2555648b5bddecd381.ab63166812c9de54fc135173738e276f6bb891890ea40df06add2f9fa5f152cb\n",
      "loading file https://huggingface.co/pitiwat/argument_wangchanberta/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/pitiwat/argument_wangchanberta/resolve/main/special_tokens_map.json from cache at /home/mike/.cache/huggingface/transformers/3306b7c4423f555327e5e5aaad9b438559e3ccff585ef7e9ab9d9681151c65d2.f205401a3c03892a215cbf4ca4f121cde3dc5b29139e8df3e4d91e1e82096ed5\n",
      "loading file https://huggingface.co/pitiwat/argument_wangchanberta/resolve/main/tokenizer_config.json from cache at /home/mike/.cache/huggingface/transformers/30e37bcaddf23dc4d48bde7e7b43441d35cbc5cae1a0a7a19b557a5120d0723a.293892e6186192dda5d30f9be747378a03e2eb8abd22d2feb1d1611341daa426\n",
      "loading configuration file https://huggingface.co/pitiwat/argument_wangchanberta/resolve/main/config.json from cache at /home/mike/.cache/huggingface/transformers/a5939c00832ab73e8ce00ae7383f75c75b6b596f05a16e648bb6184e453e97d9.b9b3c8664aa43c881e7aba11497b93ddbe97cccc5285591c094c7b3e1770512f\n",
      "Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"pitiwat/argument_wangchanberta\",\n",
      "  \"architectures\": [\n",
      "    \"CamembertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-CLAIM\",\n",
      "    \"2\": \"I-CLAIM\",\n",
      "    \"3\": \"B-PREMIST\",\n",
      "    \"4\": \"I-PREMIST\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_head\": 12,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 25005\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pitiwat/argument_wangchanberta/resolve/main/pytorch_model.bin from cache at /home/mike/.cache/huggingface/transformers/0913f6e12aa6b19bf8f53eb57ddfd1b2210fa90e194ad5b89fe0c04486d50ffb.cded87ea973dc49a387d81c2f955580b4136e1070f5b185f8b09e23e5d13e254\n",
      "All model checkpoint weights were used when initializing CamembertForTokenClassification.\n",
      "\n",
      "All the weights of CamembertForTokenClassification were initialized from the model checkpoint at pitiwat/argument_wangchanberta.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use CamembertForTokenClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer\n",
    "\n",
    "model_checkpoint = 'pitiwat/argument_wangchanberta'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,  model_max_length=480)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "trainer = Trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='โครงการแลกเปลี่ยนเดี๋ยวนี้มันเป็นธุรกิจไปหมดแล้ว เอาคำว่าสอบได้มาล่อ ถ้าไม่หัวแย่จริงๆ ยังไงก็ผ่าน แต่ก็ต้องไปจ่ายเพิ่มอีกหลายแสน แถมกลับมาก็ต้องซ้ำชั้นอีกทุนของจริงมันต้องไม่ให้เราจ่ายอะไรเลยหรือจ่ายน้อยมาก แล้วก็เรียนได้วุฒิกลับมาเลย ไม่ใช่แค่ไปแลกเปลี่ยนไม่กี่เดือน ที่สำคัญคือคนที่สอบทุนแบบนี้ได้คือคนที่เก่งจริง เพราะผู้ออกทุนเขาก็ต้องการคนที่คู่ควรที่สุดเท่านั้นเหมือนกัน ส่วนเรื่องต่อต้านไม่ขอพูดถึง'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['โครงการ', 'แลกเปลี่ยน', 'เดี๋ยวนี้', 'มัน', 'เป็น', 'ธุรกิจ', 'ไป', 'หมด', 'แล้ว', ' ', 'เอา', 'คำ', 'ว่า', 'สอบ', 'ได้มา', 'ล่อ', ' ', 'ถ้า', 'ไม่', 'หัว', 'แย่', 'จริงๆ', ' ', 'ยังไง', 'ก็', 'ผ่าน', ' ', 'แต่', 'ก็', 'ต้อง', 'ไป', 'จ่าย', 'เพิ่ม', 'อีก', 'หลาย', 'แสน', ' ', 'แถม', 'กลับมา', 'ก็', 'ต้อง', 'ซ้ำชั้น', 'อีก', 'ทุน', 'ของจริง', 'มัน', 'ต้อง', 'ไม่', 'ให้', 'เรา', 'จ่าย', 'อะไร', 'เลย', 'หรือ', 'จ่าย', 'น้อย', 'มาก', ' ', 'แล้วก็', 'เรียน', 'ได้', 'วุฒิ', 'กลับมา', 'เลย', ' ', 'ไม่', 'ใช่', 'แค่', 'ไป', 'แลกเปลี่ยน', 'ไม่', 'กี่', 'เดือน', ' ', 'ที่', 'สำคัญ', 'คือ', 'คน', 'ที่', 'สอบ', 'ทุน', 'แบบนี้', 'ได้', 'คือ', 'คน', 'ที่', 'เก่ง', 'จริง', ' ', 'เพราะ', 'ผู้', 'ออกทุน', 'เขา', 'ก็', 'ต้อง', 'การคน', 'ที่', 'คู่ควร', 'ที่สุด', 'เท่านั้น', 'เหมือนกัน', ' ', 'ส่วน', 'เรื่อง', 'ต่อต้าน', 'ไม่', 'ขอ', 'พูดถึง']\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "text_list = word_tokenize(text)\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [5, 10, 304, 10, 2823, 10, 2620, 661, 10, 17, 10, 670, 10, 28, 10, 408, 627, 10, 1722, 14660, 10, 27, 10, 1097, 10, 4448, 10, 7258, 10, 391, 729, 10, 303, 10, 1892, 6936, 10, 10, 608, 1917, 10, 199, 10, 294, 1917, 2374, 10, 28, 10, 840, 10, 286, 10, 93, 10, 414, 10, 1026, 10, 10503, 10, 374, 1917, 2374, 10, 1687, 232, 10, 93, 10, 1652, 10, 7823, 661, 2374, 729, 10, 21, 456, 10, 840, 10, 118, 10, 48, 10, 31, 10, 840, 10, 424, 10, 82, 10, 5951, 10, 384, 10, 15, 10, 2909, 10, 374, 10, 48, 10, 729, 1551, 2700, 10, 28, 10, 2823, 729, 10, 2149, 10, 219, 10, 10, 12, 10, 576, 2168, 2246, 10, 12, 10, 1097, 10, 1652, 10, 227, 10, 15, 2168, 2246, 10, 12, 10, 948, 6100, 10, 474, 4443, 10, 133, 1652, 708, 1917, 2374, 1008, 39, 10, 12, 10, 493, 490, 10, 520, 10, 268, 10, 347, 10, 636, 4218, 10, 1541, 729, 1212, 10, 1074, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['<s>', '▁', 'โครงการ', '▁', 'แลกเปลี่ยน', '▁', 'เดี๋ยวนี้', '▁มัน', '▁', 'เป็น', '▁', 'ธุรกิจ', '▁', 'ไป', '▁', 'หมด', '▁แล้ว', '▁', '▁เอา', '▁คํา', '▁', 'ว่า', '▁', 'สอบ', '▁', 'ได้มา', '▁', 'ล่อ', '▁', '▁ถ้า', '▁ไม่', '▁', 'หัว', '▁', 'แย่', '▁จริงๆ', '▁', '▁', 'ยังไง', '▁ก็', '▁', 'ผ่าน', '▁', '▁แต่', '▁ก็', '▁ต้อง', '▁', 'ไป', '▁', 'จ่าย', '▁', 'เพิ่ม', '▁', 'อีก', '▁', 'หลาย', '▁', 'แสน', '▁', '▁แถม', '▁', 'กลับมา', '▁ก็', '▁ต้อง', '▁', 'ซ้ํา', 'ชั้น', '▁', 'อีก', '▁', 'ทุน', '▁', 'ของจริง', '▁มัน', '▁ต้อง', '▁ไม่', '▁', 'ให้', '▁เรา', '▁', 'จ่าย', '▁', 'อะไร', '▁', 'เลย', '▁', 'หรือ', '▁', 'จ่าย', '▁', 'น้อย', '▁', 'มาก', '▁', '▁แล้วก็', '▁', 'เรียน', '▁', 'ได้', '▁', 'วุฒิ', '▁', 'กลับมา', '▁', 'เลย', '▁', '▁ไม่', '▁ใช่', '▁แค่', '▁', 'ไป', '▁', 'แลกเปลี่ยน', '▁ไม่', '▁', 'กี่', '▁', 'เดือน', '▁', '▁', 'ที่', '▁', 'สําคัญ', '▁คือ', '▁คน', '▁', 'ที่', '▁', 'สอบ', '▁', 'ทุน', '▁', 'แบบนี้', '▁', 'ได้', '▁คือ', '▁คน', '▁', 'ที่', '▁', 'เก่ง', '▁จริง', '▁', '▁เพราะ', '▁ผู้', '▁', 'ออก', 'ทุน', '▁เขา', '▁ก็', '▁ต้อง', '▁การ', 'คน', '▁', 'ที่', '▁', 'คู่', 'ควร', '▁', 'ที่สุด', '▁', 'เท่านั้น', '▁', 'เหมือนกัน', '▁', '▁ส่วน', '▁เรื่อง', '▁', 'ต่อต้าน', '▁ไม่', '▁ขอ', '▁', 'พูดถึง', '</s>']\n"
     ]
    }
   ],
   "source": [
    "_input_token = tokenizer(text_list, is_split_into_words=True)\n",
    "_word_token = tokenizer.convert_ids_to_tokens(_input_token[\"input_ids\"])\n",
    "print(_input_token)\n",
    "print(_word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[4, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred = trainer.predict([_input_token])[0]\n",
    "pred = np.argmax(pred, axis=2)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-p', 'B-c', 'B-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-p', 'O', 'O', 'B-c', 'B-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p']\n"
     ]
    }
   ],
   "source": [
    "label_list = ['O', 'B-c', 'I-c', 'B-p', 'I-p']\n",
    "true_predictions = [label_list[l] for l in pred[0]]\n",
    "print(true_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print(len(true_predictions))\n",
    "print(len(_word_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('▁', 'I-p')\n",
      "('โครงการ', 'B-c')\n",
      "('▁', 'B-c')\n",
      "('แลกเปลี่ยน', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('เดี๋ยวนี้', 'I-c')\n",
      "('▁มัน', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('เป็น', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('ธุรกิจ', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('ไป', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('หมด', 'I-c')\n",
      "('▁แล้ว', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('▁เอา', 'O')\n",
      "('▁คํา', 'B-p')\n",
      "('▁', 'I-p')\n",
      "('ว่า', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('สอบ', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ได้มา', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ล่อ', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('▁ถ้า', 'I-p')\n",
      "('▁ไม่', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('หัว', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('แย่', 'I-p')\n",
      "('▁จริงๆ', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ยังไง', 'I-p')\n",
      "('▁ก็', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ผ่าน', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('▁แต่', 'I-p')\n",
      "('▁ก็', 'I-p')\n",
      "('▁ต้อง', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ไป', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('จ่าย', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('เพิ่ม', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('อีก', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('หลาย', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('แสน', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('▁แถม', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('กลับมา', 'I-p')\n",
      "('▁ก็', 'I-p')\n",
      "('▁ต้อง', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ซ้ํา', 'I-p')\n",
      "('ชั้น', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('อีก', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ทุน', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ของจริง', 'I-p')\n",
      "('▁มัน', 'I-p')\n",
      "('▁ต้อง', 'I-p')\n",
      "('▁ไม่', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ให้', 'I-p')\n",
      "('▁เรา', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('จ่าย', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('อะไร', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('เลย', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('หรือ', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('จ่าย', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('น้อย', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('มาก', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('▁แล้วก็', 'O')\n",
      "('▁', 'O')\n",
      "('เรียน', 'O')\n",
      "('▁', 'O')\n",
      "('ได้', 'O')\n",
      "('▁', 'O')\n",
      "('วุฒิ', 'O')\n",
      "('▁', 'O')\n",
      "('กลับมา', 'O')\n",
      "('▁', 'O')\n",
      "('เลย', 'O')\n",
      "('▁', 'O')\n",
      "('▁ไม่', 'O')\n",
      "('▁ใช่', 'O')\n",
      "('▁แค่', 'O')\n",
      "('▁', 'O')\n",
      "('ไป', 'O')\n",
      "('▁', 'O')\n",
      "('แลกเปลี่ยน', 'O')\n",
      "('▁ไม่', 'O')\n",
      "('▁', 'O')\n",
      "('กี่', 'O')\n",
      "('▁', 'O')\n",
      "('เดือน', 'I-p')\n",
      "('▁', 'O')\n",
      "('▁', 'O')\n",
      "('ที่', 'B-c')\n",
      "('▁', 'B-c')\n",
      "('สําคัญ', 'I-c')\n",
      "('▁คือ', 'I-c')\n",
      "('▁คน', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('ที่', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('สอบ', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('ทุน', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('แบบนี้', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('ได้', 'I-c')\n",
      "('▁คือ', 'I-c')\n",
      "('▁คน', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('ที่', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('เก่ง', 'I-c')\n",
      "('▁จริง', 'I-c')\n",
      "('▁', 'I-c')\n",
      "('▁เพราะ', 'O')\n",
      "('▁ผู้', 'B-p')\n",
      "('▁', 'I-p')\n",
      "('ออก', 'I-p')\n",
      "('ทุน', 'I-p')\n",
      "('▁เขา', 'I-p')\n",
      "('▁ก็', 'I-p')\n",
      "('▁ต้อง', 'I-p')\n",
      "('▁การ', 'I-p')\n",
      "('คน', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ที่', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('คู่', 'I-p')\n",
      "('ควร', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ที่สุด', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('เท่านั้น', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('เหมือนกัน', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('▁ส่วน', 'I-p')\n",
      "('▁เรื่อง', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ต่อต้าน', 'I-p')\n",
      "('▁ไม่', 'I-p')\n",
      "('▁ขอ', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('พูดถึง', 'I-p')\n"
     ]
    }
   ],
   "source": [
    "tag_text = []\n",
    "for w, l in zip(_word_token[1:-1], true_predictions):\n",
    "  print((w, l))\n",
    "  tag_text.append((w, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('โครงการ', 'B-c')\n",
      "('แลกเปลี่ยน', 'I-c')\n",
      "('เดี๋ยวนี้', 'I-c')\n",
      "('มัน', 'I-c')\n",
      "('เป็น', 'I-c')\n",
      "('ธุรกิจ', 'I-c')\n",
      "('ไป', 'I-c')\n",
      "('หมด', 'I-c')\n",
      "('แล้ว', 'I-c')\n",
      "(' ', 'I-c')\n",
      "('เอา', 'O')\n",
      "('คำ', 'B-p')\n",
      "('ว่า', 'I-p')\n",
      "('สอบ', 'I-p')\n",
      "('ได้มา', 'I-p')\n",
      "('ล่อ', 'I-p')\n",
      "(' ', 'I-p')\n",
      "('ถ้า', 'I-p')\n",
      "('ไม่', 'I-p')\n",
      "('หัว', 'I-p')\n",
      "('แย่', 'I-p')\n",
      "('จริงๆ', 'I-p')\n",
      "(' ', 'I-p')\n",
      "('ยังไง', 'I-p')\n",
      "('ก็', 'I-p')\n",
      "('ผ่าน', 'I-p')\n",
      "(' ', 'I-p')\n",
      "('แต่', 'I-p')\n",
      "('ก็', 'I-p')\n",
      "('ต้อง', 'I-p')\n",
      "('ไป', 'I-p')\n",
      "('จ่าย', 'I-p')\n",
      "('เพิ่ม', 'I-p')\n",
      "('อีก', 'I-p')\n",
      "('หลาย', 'I-p')\n",
      "('แสน', 'I-p')\n",
      "(' ', 'I-p')\n",
      "('แถม', 'I-p')\n",
      "('กลับมา', 'I-p')\n",
      "('ก็', 'I-p')\n",
      "('ต้อง', 'I-p')\n",
      "('ซ้ำชั้น', 'I-p')\n",
      "('อีก', 'I-p')\n",
      "('ทุน', 'I-p')\n",
      "('ของจริง', 'I-p')\n",
      "('มัน', 'I-p')\n",
      "('ต้อง', 'I-p')\n",
      "('ไม่', 'I-p')\n",
      "('ให้', 'I-p')\n",
      "('เรา', 'I-p')\n",
      "('จ่าย', 'I-p')\n",
      "('อะไร', 'I-p')\n",
      "('เลย', 'I-p')\n",
      "('หรือ', 'I-p')\n",
      "('จ่าย', 'I-p')\n",
      "('น้อย', 'I-p')\n",
      "('มาก', 'I-p')\n",
      "(' ', 'I-p')\n",
      "('แล้วก็', 'O')\n",
      "('เรียน', 'O')\n",
      "('ได้', 'O')\n",
      "('วุฒิ', 'O')\n",
      "('กลับมา', 'O')\n",
      "('เลย', 'O')\n",
      "(' ', 'O')\n",
      "('ไม่', 'O')\n",
      "('ใช่', 'O')\n",
      "('แค่', 'O')\n",
      "('ไป', 'O')\n",
      "('แลกเปลี่ยน', 'O')\n",
      "('ไม่', 'O')\n",
      "('กี่', 'O')\n",
      "('เดือน', 'I-p')\n",
      "(' ', 'O')\n",
      "('ที่', 'B-c')\n",
      "('สำคัญ', 'I-c')\n",
      "('คือ', 'I-c')\n",
      "('คน', 'I-c')\n",
      "('ที่', 'I-c')\n",
      "('สอบ', 'I-c')\n",
      "('ทุน', 'I-c')\n",
      "('แบบนี้', 'I-c')\n",
      "('ได้', 'I-c')\n",
      "('คือ', 'I-c')\n",
      "('คน', 'I-c')\n",
      "('ที่', 'I-c')\n",
      "('เก่ง', 'I-c')\n",
      "('จริง', 'I-c')\n",
      "(' ', 'I-c')\n",
      "('เพราะ', 'O')\n",
      "('ผู้', 'B-p')\n",
      "('ออกทุน', 'I-p')\n",
      "('เขา', 'I-p')\n",
      "('ก็', 'I-p')\n",
      "('ต้อง', 'I-p')\n",
      "('การคน', 'I-p')\n",
      "('ที่', 'I-p')\n",
      "('คู่ควร', 'I-p')\n",
      "('ที่สุด', 'I-p')\n",
      "('เท่านั้น', 'I-p')\n",
      "('เหมือนกัน', 'I-p')\n",
      "(' ', 'I-p')\n",
      "('ส่วน', 'I-p')\n",
      "('เรื่อง', 'I-p')\n",
      "('ต่อต้าน', 'I-p')\n",
      "('ไม่', 'I-p')\n",
      "('ขอ', 'I-p')\n",
      "('พูดถึง', 'I-p')\n"
     ]
    }
   ],
   "source": [
    "tag_pred = [None] * len(text_list)\n",
    "for i, ids in enumerate(_input_token.word_ids()[1:-1]):\n",
    "    tag_pred[ids] = tag_text[i][1]\n",
    "\n",
    "for w, l in zip(text_list, tag_pred):\n",
    "    print((w, l))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "018e0a3ac4678c6eee4f5b6012f6866bd583f46fe819b31cdc8524b9233bdcf3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wangchan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
