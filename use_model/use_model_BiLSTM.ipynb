{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55005bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save / Load File\n",
    "import dill\n",
    "import pickle\n",
    "\n",
    "# Load Vectors\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Utility\n",
    "import numpy as np\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Keras Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input ,LSTM, Embedding, Dense, TimeDistributed, Dropout, Conv1D\n",
    "from tensorflow.keras.layers import Bidirectional, concatenate, SpatialDropout1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "492c7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../trained_model/BiLSTM/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38139d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thai2fit_model = KeyedVectors.load_word2vec_format('../thai2vec/thai2vecNoSym.bin',binary=True)\n",
    "thai2fit_weight = thai2fit_model.vectors\n",
    "\n",
    "thai2dict = {}\n",
    "\n",
    "for word in thai2fit_model.index_to_key:\n",
    "    thai2dict[word] = thai2fit_model[word]\n",
    "\n",
    "all_thai2dict = sorted(set(thai2dict))\n",
    "thai2dict_to_ix = dict((c, i) for i, c in enumerate(thai2dict)) #convert thai2fit to index \n",
    "ix_to_thai2dict = dict((v,k) for k,v in thai2dict_to_ix.items())  #convert index to thai2fit\n",
    "\n",
    "n_thai2dict = len(thai2dict_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4cb5663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path+'nerdict.pickle', 'rb') as nerdict:\n",
    "    ner_to_ix = pickle.load(nerdict)\n",
    "\n",
    "ix_to_ner = dict((v,k) for k,v in ner_to_ix.items())  #convert index to ner\n",
    "n_tag = len(ner_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4033fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path+'chardict.pickle', 'rb') as chardict:\n",
    "    char2idx = pickle.load(chardict)\n",
    "\n",
    "n_chars = len(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b69edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 400\n",
    "max_len_char = 32\n",
    "\n",
    "character_LSTM_unit = 32\n",
    "char_embedding_dim = 32\n",
    "main_lstm_unit = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d951a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_word(list_sent):\n",
    "    idxs = list()\n",
    "    for word in list_sent:\n",
    "        if word in thai2dict:\n",
    "            idxs.append(thai2dict_to_ix[word])\n",
    "        else:\n",
    "            idxs.append(thai2dict_to_ix[\"unknown\"]) #Use UNK tag for unknown word\n",
    "    return idxs\n",
    "\n",
    "def prepare_sequence_target(input_label):\n",
    "    idxs = [ner_to_idx[BIO] for BIO in input_label]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c2465e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word Input\n",
    "word_in = Input(shape=(max_len), name='word_input_')\n",
    "\n",
    "#word Enbedding Using Thai2Fit\n",
    "word_embeddings = Embedding(input_dim=n_thai2dict, output_dim=400, weights = [thai2fit_weight], input_length=max_len,\n",
    "                                               mask_zero=False, trainable=False, name=\"word_embedding\")(word_in)\n",
    "\n",
    "# Character Input\n",
    "char_in = Input(shape=(max_len, max_len_char,), name='char_input')\n",
    "\n",
    "# Character Embedding\n",
    "emb_char = TimeDistributed(Embedding(input_dim=n_chars, output_dim=char_embedding_dim, \n",
    "                           input_length=max_len_char, mask_zero=False))(char_in)\n",
    "\n",
    "# Character Sequence to Vector via BiLSTM\n",
    "char_enc = TimeDistributed(Bidirectional(LSTM(units=character_LSTM_unit, return_sequences=False)))(emb_char)\n",
    "\n",
    "# Concatenate All Embedding\n",
    "all_word_embeddings = concatenate([word_embeddings, char_enc])\n",
    "all_word_embeddings = SpatialDropout1D(0.3)(all_word_embeddings)\n",
    "\n",
    "main_lstm = Bidirectional(LSTM(units=main_lstm_unit, return_sequences=True,))(all_word_embeddings)\n",
    "dens = TimeDistributed(Dense(100, activation=\"relu\"))(main_lstm)\n",
    "out = Dense(n_tag, activation=\"softmax\")(dens)\n",
    "model = keras.Model(inputs=[word_in, char_in], outputs=[out])\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88a75dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path+\"model_BiLSTM.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdb789e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word_to_char(predict_word):\n",
    "    predict_char = []\n",
    "    sent_seq = []\n",
    "    for i in range(max_len):\n",
    "        word_seq = []\n",
    "        for j in range(max_len_char):    \n",
    "            try:\n",
    "                if(predict_word[i][j] in char2idx):\n",
    "                    word_seq.append(char2idx.get(predict_word[i][j]))\n",
    "                else:\n",
    "                    word_seq.append(char2idx.get(\"unknown\"))\n",
    "            except:\n",
    "                word_seq.append(char2idx.get(\"pad\"))\n",
    "        sent_seq.append(word_seq)\n",
    "    predict_char.append(np.array(sent_seq))\n",
    "    \n",
    "    return predict_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55a247c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_html_format2(pred_list):\n",
    "    LIST_TAGS = ['claim', 'premise', 'o']\n",
    "    REPRESEN_TAGS = ['c', 'p', 'O']\n",
    "    text_convert = ''\n",
    "    prev_tag = ''\n",
    "    trigger_tag = False \n",
    "\n",
    "\n",
    "    for word, label in pred_list:\n",
    "        tags = label.split('-')\n",
    "        next_tag = tags[0] if len(tags) == 1 else tags[1]\n",
    "        \n",
    "        if prev_tag != next_tag:\n",
    "            if prev_tag:\n",
    "                text_convert += '</' + html_tag + '>'\n",
    "\n",
    "            html_tag = LIST_TAGS[REPRESEN_TAGS.index(next_tag)]\n",
    "            prev_tag = next_tag\n",
    "            trigger_tag = not(trigger_tag)\n",
    "\n",
    "            if trigger_tag:\n",
    "                text_convert += '<' + html_tag + '>'\n",
    "            else:\n",
    "                text_convert += '<' + html_tag + '>'\n",
    "\n",
    "        text_convert += word\n",
    "    text_convert += '</'+ LIST_TAGS[REPRESEN_TAGS.index(prev_tag)]+'>'\n",
    "    text_convert = text_convert.replace('<o>', '').replace('</o>', '')\n",
    "            \n",
    "    return text_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a4483cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepocess_text(text, token=True):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    if token == True:\n",
    "        text = word_tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be1e1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    predict_sent = prepocess_text(text)\n",
    "    len_word = len(predict_sent)\n",
    "    predict_word = []\n",
    "    predict_word = [prepare_sequence_word(predict_sent)]\n",
    "    predict_word = pad_sequences(maxlen=max_len, sequences=predict_word, value=thai2dict_to_ix[\"pad\"], padding='post', truncating='post')\n",
    "\n",
    "    predict_char = convert_word_to_char(predict_sent)\n",
    "    result_tag = model.predict([predict_word,np.array(predict_char).reshape((len(predict_char),max_len, max_len_char))])\n",
    "    p = np.argmax(result_tag, axis=-1)\n",
    "    pred=[i for i in p[0]]\n",
    "    revert_pred=[ix_to_ner[i] for i in p[0]]\n",
    "    \n",
    "    word=predict_sent\n",
    "    tag=revert_pred[:len_word]\n",
    "    return word, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d49733db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<claim>ทำงานดีกว่าเรียน </claim><premise>เพราะได้ผลตอบแทนถ้าเรียนผลแค่สอบผ่านยังไงก็ทำงานอยู่ดีเมื่อจบ</premise>'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'ทำงานดีกว่าเรียน เพราะได้ผลตอบแทนถ้าเรียนผลแค่สอบผ่านยังไงก็ทำงานอยู่ดีเมื่อจบ'\n",
    "list_word, predict_tag = prediction(text)\n",
    "tag_html_format2(zip(list_word, predict_tag))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
